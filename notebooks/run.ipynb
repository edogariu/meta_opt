{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7de4653-cd5d-459c-96e2-7963793b6a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evandogariu/Desktop/meta-opt/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from meta_opt.train_loops import train_standard_opt, train_hgd, train_meta_opt\n",
    "from meta_opt.utils.experiment_utils import make, save_checkpoint, process_results, bcolors, plot, get_final_cparams\n",
    "from meta_opt import DIR\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dill as pkl\n",
    "import optax\n",
    "\n",
    "# ==================================================\n",
    "# configuration and seeds for each trial\n",
    "SEEDS = [5, 6, 7, 8, 9]\n",
    "\n",
    "NAME = 'mnist_fullbatch_baselines'\n",
    "CFG = {\n",
    "    # training options\n",
    "    'workload': 'MNIST',\n",
    "    'num_iters': 10000,\n",
    "    'eval_every': -1,\n",
    "    'num_eval_iters': -1,\n",
    "    'batch_size': 512,\n",
    "    'full_batch': True,\n",
    "    'reset_every': 500,\n",
    "\n",
    "    # experiment options\n",
    "    'experiment_name': NAME,\n",
    "    'load_checkpoint': False,\n",
    "    'overwrite': True,  # whether to allow us to overwrite existing checkpoints or throw errors\n",
    "    'directory': DIR + '/..',\n",
    "}\n",
    "\n",
    "def run(seeds, cfg):\n",
    "    results = make(cfg)\n",
    "    \n",
    "    # uncomment the ones to run, with correctly chosen hyperparameters\n",
    "    for s in seeds:\n",
    "        CFG['seed'] = s\n",
    "        print(f'running with seed {s}')\n",
    "        \n",
    "        # # ours\n",
    "        # opt = optax.inject_hyperparams(optax.adamw)(learning_rate=1e-3)\n",
    "        # results['ours_1e-3'].append(train_meta_opt(CFG, counterfactual=True, H=32, HH=2, meta_optimizer=opt))\n",
    "\n",
    "        # standard benchmarks\n",
    "        benchmarks = {\n",
    "            # 'sgd': optax.inject_hyperparams(optax.sgd)(learning_rate=0.4),\n",
    "            # 'momentum': optax.chain(optax.add_decayed_weights(1e-4), optax.inject_hyperparams(optax.sgd)(learning_rate=0.1, momentum=0.9)),\n",
    "            # 'adamw': optax.inject_hyperparams(optax.adamw)(learning_rate=1e-3, b1=0.9, b2=0.999, weight_decay=1e-4),\n",
    "            'dog': optax.inject_hyperparams(optax.contrib.dog)(0.5),\n",
    "            'dowg': optax.inject_hyperparams(optax.contrib.dowg)(0.5),\n",
    "            'dadamw': optax.inject_hyperparams(optax.contrib.dadapt_adamw)(),\n",
    "            'mechsgd': optax.contrib.mechanize(optax.inject_hyperparams(optax.sgd)(learning_rate=0.4)),\n",
    "            'mechadamw': optax.contrib.mechanize(optax.inject_hyperparams(optax.adamw)(learning_rate=1e-3, b1=0.9, b2=0.999, weight_decay=1e-4)),\n",
    "        }\n",
    "        for k, opt in benchmarks.items(): results[k].append(train_standard_opt(CFG, opt))\n",
    "\n",
    "        # # other\n",
    "        # results['hgd'].append(train_hgd(CFG, initial_lr=0.4, hypergrad_lr=1e-4))\n",
    "\n",
    "        save_checkpoint(CFG, results, checkpoint_name=f'seed {s}')\n",
    "    processed_results = process_results(CFG, results)\n",
    "    return processed_results\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef24476-e73c-49da-99e5-b0903562dd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \u001b[93m\u001b[1mcpu\u001b[0m for jax\n",
      "results will be stored at: \u001b[96m\u001b[1m/Users/evandogariu/Desktop/meta-opt/notebooks/../data/mnist_fullbatch_baselines_*.pkl\u001b[0m\n",
      "we will \u001b[91m\u001b[1mNOT\u001b[0m try to load experiment checkpoint first\n",
      "starting the experiment from scratch :)\n",
      "\u001b[91m\u001b[1mnote: using full_batch means we will never eval\u001b[0m\n",
      "running with seed 5\n",
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:11:29.486520: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "100%|█████████████████████████████████████████████████████████████████| 10000/10000 [00:27<00:00, 365.09it/s, loss=0.01, eval_loss=N/A, lr=0.5]2024-05-28 04:11:56.833015: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:11:56.923924: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "100%|████████████████████████████████████████████████████████████████| 10000/10000 [00:28<00:00, 354.68it/s, loss=0.002, eval_loss=N/A, lr=0.5]2024-05-28 04:12:25.083367: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:12:25.188219: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "100%|██████████████████████████████████████████████████████████████████████▉| 9985/10000 [00:27<00:00, 373.03it/s, loss=0, eval_loss=N/A, lr=1]2024-05-28 04:12:52.547256: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|██████████████████████████████████████████████████████████████████████| 10000/10000 [00:27<00:00, 364.99it/s, loss=0, eval_loss=N/A, lr=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:12:52.675514: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "100%|██████████████████████████████████████████████████████████████████████| 10000/10000 [00:27<00:00, 366.29it/s, loss=0, eval_loss=N/A, lr=0]2024-05-28 04:13:19.931407: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:13:20.213582: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "100%|██████████████████████████████████████████████████████████████████████▊| 9969/10000 [00:28<00:00, 357.20it/s, loss=0, eval_loss=N/A, lr=0]2024-05-28 04:13:48.653666: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|██████████████████████████████████████████████████████████████████████| 10000/10000 [00:28<00:00, 351.02it/s, loss=0, eval_loss=N/A, lr=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mSaved checkpoint seed 5 to /Users/evandogariu/Desktop/meta-opt/notebooks/../data/mnist_fullbatch_baselines_raw.pkl\u001b[0m\n",
      "running with seed 6\n",
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:13:51.883541: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "100%|████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 380.74it/s, loss=0.008, eval_loss=N/A, lr=0.5]2024-05-28 04:14:18.099494: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:14:18.207867: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "100%|████████████████████████████████████████████████████████████████▊| 9972/10000 [00:26<00:00, 398.50it/s, loss=0.002, eval_loss=N/A, lr=0.5]2024-05-28 04:14:44.543589: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "100%|████████████████████████████████████████████████████████████████| 10000/10000 [00:26<00:00, 378.96it/s, loss=0.002, eval_loss=N/A, lr=0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89610 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/10000 [00:00<?, ?it/s]2024-05-28 04:14:44.655002: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      " 40%|████████████████████████████▋                                          | 4036/10000 [00:11<00:15, 375.97it/s, loss=0, eval_loss=N/A, lr=1]"
     ]
    }
   ],
   "source": [
    "processed_results = run(SEEDS, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c82309-9066-4900-a91b-25e2fb6805cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "keys_to_plot = {\n",
    "    # 'sgd': 'sgd',\n",
    "    # 'momentum': 'momentum',\n",
    "    # 'hgd': 'hgd',\n",
    "    # 'adamw': 'adamw',\n",
    "    'dog': 'dog',\n",
    "    'dowg': 'dowg',\n",
    "    # 'dadamw': 'dadamw',\n",
    "    # 'ours_1e-3': 'ours',\n",
    "    # 'mechsgd': 'mechsgd',\n",
    "    # 'mechadam': 'mechadam'\n",
    "}\n",
    "# keys_to_plot = '.*ours.*'\n",
    "\n",
    "plots_to_make = {\n",
    "              'loss': 'Train Loss',\n",
    "              # 'M': 'Learned Coefficients',\n",
    "              # 'grad_sq_norm': 'Sq Grad Norm',\n",
    "              # 'proj_grad_sq_norm': 'Proj Sq Grad Norm',\n",
    "}\n",
    "\n",
    "# processed_results = pkl.load(open('{}/data/{}_processed.pkl'.format(CFG['directory'], CFG['experiment_name']), 'rb'))\n",
    "# for b in baselines: processed_results = append_results(processed_results, b)\n",
    "    \n",
    "(fig, ax), anim = plot(None, processed_results, keys_to_plot, plots_to_make, \n",
    "                       anim_bounds=None, smoothing=None, highlight_baselines=True, fontsize=20, legend_location='upper left')\n",
    "ax[0].set_ylim(0, 0.005)\n",
    "# ax[0].set_xlim(5000, 9500)\n",
    "# ax[1].set_xlim(0, 31)\n",
    "# ax[1].set_ylim(-0.1, 0.005)\n",
    "# ax[1].legend(loc='lower right', fontsize=20)\n",
    "# plt.savefig('{}/figs/{}.pdf'.format(CFG['directory'], 'mnist_fullbatch_simple'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metaopt",
   "language": "python",
   "name": "metaopt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
