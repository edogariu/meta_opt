{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6570ac61-11c1-4fc6-abe4-c001b3e65f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:51:27.912462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-03-13 16:51:29.841940: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    from google import colab  # for use in google colab!!    os.system('git clone https://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@github.com/edogariu/meta-opt')\n",
    "    os.system('pip install -q ./meta-opt')\n",
    "    os.system('pip install -q dill')\n",
    "    # !pip install -q jax[cuda12_pip]==0.4.20 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html  # for disabling prealloc, see https://github.com/google/jax/discussions/19014\n",
    "    os.system('pip install -q tensorflow-text ml_collections clu sentencepiece')  # for WMT\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except: pass\n",
    "\n",
    "from meta_opt.train_loops import train_standard_opt, train_hgd, train_meta_opt\n",
    "from meta_opt.utils.experiment_utils import make, save_checkpoint, process_results, bcolors, plot, get_final_cparams\n",
    "from meta_opt import DIR\n",
    "from meta_opt.workloads.wmt import rsqrt\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dill as pkl\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4809ee-1209-48f6-abdd-8473b31c7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# configuration and seeds for each trial\n",
    "SEEDS = [0,]\n",
    "\n",
    "NAME = 'wmt_base_short'\n",
    "CFG = {\n",
    "    # training options\n",
    "    'workload': 'WMT',\n",
    "    'num_iters': 100000,\n",
    "    'eval_every': 1000,\n",
    "    'num_eval_iters': 20,\n",
    "    'batch_size': 32,\n",
    "    'full_batch': False,\n",
    "    'reset_every': int(1e9),\n",
    "\n",
    "    # wmt options\n",
    "    'bleu_every': 5000,\n",
    "    'transformer_size': 'base_short',\n",
    "    \n",
    "    # experiment options\n",
    "    'experiment_name': NAME,\n",
    "    'load_checkpoint': False,\n",
    "    'overwrite': True,  # whether to allow us to overwrite existing checkpoints or throw errors\n",
    "    'directory': DIR,\n",
    "}\n",
    "\n",
    "def run(seeds, cfg):\n",
    "    results = make(cfg)\n",
    "    \n",
    "    # uncomment the ones to run, with correctly chosen hyperparameters\n",
    "    for s in seeds:\n",
    "        CFG['seed'] = s\n",
    "        print(f'running with seed {s}')\n",
    "        \n",
    "        # # ours\n",
    "        # opt = optax.inject_hyperparams(optax.sgd)(learning_rate=2e-4)\n",
    "        # results['cf'].append(train_meta_opt(CFG, counterfactual=True, H=32, HH=2, meta_optimizer=opt))\n",
    "        # results['ncf'].append(train_meta_opt(CFG, counterfactual=False, H=32, HH=2, meta_optimizer=opt))\n",
    "\n",
    "        # standard benchmarks\n",
    "        benchmarks = {\n",
    "            # 'sgd': optax.inject_hyperparams(optax.sgd)(learning_rate=0.4),\n",
    "            # 'momentum': optax.chain(optax.add_decayed_weights(1e-4), optax.inject_hyperparams(optax.sgd)(learning_rate=0.1, momentum=0.9)),\n",
    "            # 'adamw': optax.inject_hyperparams(optax.adamw)(learning_rate=4e-4, b1=0.9, b2=0.999, weight_decay=1e-4),\n",
    "            # 'rmsprop': optax.inject_hyperparams(optax.rmsprop)(learning_rate=1e-3),\n",
    "            'rsqrt': rsqrt(lr=0.004, warmup_steps=4000),\n",
    "        }\n",
    "        for k, opt in benchmarks.items(): results[k].append(train_standard_opt(CFG, opt))\n",
    "\n",
    "        # other\n",
    "        # results['hgd'].append(train_hgd(CFG, initial_lr=0.1, hypergrad_lr=1e-3))\n",
    "\n",
    "        save_checkpoint(CFG, results, checkpoint_name=f'seed {s}')\n",
    "    processed_results = process_results(CFG, results)\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd628584-11b8-4421-93a5-1d9b936b1f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \u001b[93m\u001b[1mgpu\u001b[0m for jax\n",
      "results will be stored at: \u001b[96m\u001b[1m/home/edogariu/meta-opt/data/wmt_test_*.pkl\u001b[0m\n",
      "we will \u001b[91m\u001b[1mNOT\u001b[0m try to load experiment checkpoint first\n",
      "starting the experiment from scratch :)\n",
      "running with seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 16:51:31.281728: W external/local_tsl/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5085696 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 400/24000 [02:13<1:01:07,  6.43it/s, loss=8.73, eval_loss=N/A]E0313 16:54:14.767703 2333622 pjrt_stream_executor_client.cc:2804] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2097152000 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:    4.39GiB\n",
      "              constant allocation:         0B\n",
      "        maybe_live_out allocation:    1.95GiB\n",
      "     preallocated temp allocation:         0B\n",
      "                 total allocation:    6.35GiB\n",
      "              total fragmentation:         0B (0.00%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 1.95GiB\n",
      "\t\tEntry Parameter Subshape: f32[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 1.95GiB\n",
      "\t\tEntry Parameter Subshape: f32[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 1.95GiB\n",
      "\t\tOperator: op_name=\"jit(select_n)/jit(main)/select_n\" source_file=\"/tmp/ipykernel_2333622/3895418204.py\" source_line=44\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 500.00MiB\n",
      "\t\tEntry Parameter Subshape: pred[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\n",
      "  2%|▏         | 400/24000 [02:40<2:37:56,  2.49it/s, loss=8.73, eval_loss=N/A]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 2097152000 bytes.\n",
      "BufferAssignment OOM Debugging.\n",
      "BufferAssignment stats:\n",
      "             parameter allocation:    4.39GiB\n",
      "              constant allocation:         0B\n",
      "        maybe_live_out allocation:    1.95GiB\n",
      "     preallocated temp allocation:         0B\n",
      "                 total allocation:    6.35GiB\n",
      "              total fragmentation:         0B (0.00%)\n",
      "Peak buffers:\n",
      "\tBuffer 1:\n",
      "\t\tSize: 1.95GiB\n",
      "\t\tEntry Parameter Subshape: f32[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 2:\n",
      "\t\tSize: 1.95GiB\n",
      "\t\tEntry Parameter Subshape: f32[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 3:\n",
      "\t\tSize: 1.95GiB\n",
      "\t\tOperator: op_name=\"jit(select_n)/jit(main)/select_n\" source_file=\"/tmp/ipykernel_2333622/3895418204.py\" source_line=44\n",
      "\t\tXLA Label: fusion\n",
      "\t\tShape: f32[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\tBuffer 4:\n",
      "\t\tSize: 500.00MiB\n",
      "\t\tEntry Parameter Subshape: pred[64,256,32000]\n",
      "\t\t==========================\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEEDS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 44\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(seeds, cfg)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# # ours\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# opt = optax.inject_hyperparams(optax.sgd)(learning_rate=2e-4)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# results['cf'].append(train_meta_opt(CFG, counterfactual=True, H=32, HH=2, meta_optimizer=opt))\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# results['ncf'].append(train_meta_opt(CFG, counterfactual=False, H=32, HH=2, meta_optimizer=opt))\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# standard benchmarks\u001b[39;00m\n\u001b[1;32m     38\u001b[0m benchmarks \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# 'sgd': optax.inject_hyperparams(optax.sgd)(learning_rate=0.4),\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# 'momentum': optax.chain(optax.add_decayed_weights(1e-4), optax.inject_hyperparams(optax.sgd)(learning_rate=0.1, momentum=0.9)),\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madamw\u001b[39m\u001b[38;5;124m'\u001b[39m: optax\u001b[38;5;241m.\u001b[39minject_hyperparams(optax\u001b[38;5;241m.\u001b[39madamw)(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4e-4\u001b[39m, b1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, b2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m),\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# 'rmsprop': optax.inject_hyperparams(optax.rmsprop)(learning_rate=1e-3),\u001b[39;00m\n\u001b[1;32m     43\u001b[0m }\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, opt \u001b[38;5;129;01min\u001b[39;00m benchmarks\u001b[38;5;241m.\u001b[39mitems(): results[k]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_standard_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# other\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# results['hgd'].append(train_hgd(CFG, initial_lr=0.1, hypergrad_lr=1e-3))\u001b[39;00m\n\u001b[1;32m     49\u001b[0m save_checkpoint(CFG, results, checkpoint_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/meta-opt/lib/python3.10/site-packages/meta_opt/train_loops/standard.py:40\u001b[0m, in \u001b[0;36mtrain_standard_opt\u001b[0;34m(cfg, optimizer)\u001b[0m\n\u001b[1;32m     38\u001b[0m s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;241m%\u001b[39m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_every\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m t \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_numpy_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitems(): s[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m     41\u001b[0m     s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_sq_norm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pytree_sq_norm(tstate\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m     42\u001b[0m     s[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgrad_sq_norm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pytree_sq_norm(grads)\n",
      "File \u001b[0;32m~/.conda/envs/meta-opt/lib/python3.10/site-packages/meta_opt/nn.py:92\u001b[0m, in \u001b[0;36meval\u001b[0;34m(tstate, dataset)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m eval_metrics\u001b[38;5;241m.\u001b[39mkeys(): eval_metrics[k] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(eval_metrics)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "run(SEEDS, CFG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-opt [~/.conda/envs/meta-opt/]",
   "language": "python",
   "name": "conda_meta-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
