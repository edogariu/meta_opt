{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9775a7f9-04f5-40ba-a288-58d84bc60212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9999972   0.9999984   0.9999928  ...  0.99999154 -0.9999979\n",
      "   0.9999984 ]\n",
      " [ 0.9999944   0.9999962  -0.99999875 ...  0.9999359  -0.999998\n",
      "  -0.99999326]\n",
      " [ 0.99999154  0.99999774 -0.9999925  ...  0.99999607 -0.99999714\n",
      "  -0.9999989 ]\n",
      " ...\n",
      " [-0.9999966   0.9999927  -0.9999974  ... -0.9999951  -0.9999941\n",
      "   0.99999774]\n",
      " [-0.99999803 -0.99999654  0.9999914  ... -0.9999981   0.9999939\n",
      "  -0.9999802 ]\n",
      " [-0.9999955  -0.9999966  -0.9999978  ...  0.9999968  -0.99999505\n",
      "   0.9999965 ]]\n",
      "[[ 1.  1.  1. ...  1. -1.  1.]\n",
      " [ 1.  1. -1. ...  1. -1. -1.]\n",
      " [ 1.  1. -1. ...  1. -1. -1.]\n",
      " ...\n",
      " [-1.  1. -1. ... -1. -1.  1.]\n",
      " [-1. -1.  1. ... -1.  1. -1.]\n",
      " [-1. -1. -1. ...  1. -1.  1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optax\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "x = jnp.array(np.random.randn(500, 200))\n",
    "b2 = 0\n",
    "\n",
    "# automatic\n",
    "opt = optax.scale_by_adam(b1=0, b2=b2)\n",
    "opt_state = opt.init(x)\n",
    "\n",
    "# manual\n",
    "nu = jnp.zeros_like(x)\n",
    "\n",
    "def loss(_x): return (_x * _x).sum() ** 0.5\n",
    "errs = []\n",
    "for _ in range(1000):\n",
    "    grads = jax.grad(loss)(x)\n",
    "\n",
    "    g_auto, opt_state = opt.update(grads, opt_state)\n",
    "\n",
    "    nu = b2 * nu + (1 - b2) * (grads ** 2)\n",
    "    g_manual = grads / (nu ** 0.5)\n",
    "\n",
    "    error = jnp.linalg.norm(g_auto - g_manual)\n",
    "    print(g_auto)\n",
    "    print(g_manual)\n",
    "    print()\n",
    "    break\n",
    "    errs.append(error)\n",
    "# plt.plot(range(len(errs)), errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca9724-4e3f-42f3-bbab-5554c60c3313",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6570ac61-11c1-4fc6-abe4-c001b3e65f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project IS NOT JITTED\n",
      "_compute_control_scalar IS NOT JITTED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "try:\n",
    "    from google import colab  # for use in google colab!!    os.system('git clone https://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@github.com/edogariu/meta-opt')\n",
    "    os.system('pip install -q ./meta-opt')\n",
    "    os.system('pip install -q dill')\n",
    "    # !pip install -q jax[cuda12_pip]==0.4.20 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html  # for disabling prealloc, see https://github.com/google/jax/discussions/19014\n",
    "    os.system('pip install -q tensorflow-text ml_collections clu sentencepiece')  # for WMT\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "except: pass\n",
    "\n",
    "from meta_opt.train_loops import train_standard_opt, train_hgd, train_meta_opt\n",
    "from meta_opt.utils.experiment_utils import make, save_checkpoint, process_results, bcolors, plot, get_final_cparams\n",
    "from meta_opt import DIR\n",
    "from meta_opt.workloads.wmt import rsqrt\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dill as pkl\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4809ee-1209-48f6-abdd-8473b31c7edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================================================\n",
    "# configuration and seeds for each trial\n",
    "SEEDS = [7,]\n",
    "\n",
    "NAME = 'yeet'\n",
    "CFG = {\n",
    "    # training options\n",
    "    'workload': 'CIFAR',\n",
    "    'num_iters': 10000,\n",
    "    'eval_every': 100,\n",
    "    'num_eval_iters': -1,\n",
    "    'batch_size': 256,\n",
    "    'full_batch': False,\n",
    "    'reset_every': 10000,\n",
    "\n",
    "    # # wmt options\n",
    "    # 'bleu_every': 5000,\n",
    "    # 'transformer_size': 'base_short',\n",
    "    \n",
    "    # experiment options\n",
    "    'experiment_name': NAME,\n",
    "    'load_checkpoint': False,\n",
    "    'overwrite': True,  # whether to allow us to overwrite existing checkpoints or throw errors\n",
    "    'directory': f'{DIR}/..',\n",
    "}\n",
    "\n",
    "def run(seeds, cfg):\n",
    "    results = make(cfg)\n",
    "\n",
    "    processed_results = pkl.load(open('{}/data/ncq_test_processed.pkl'.format(cfg['directory']), 'rb'))\n",
    "    initial_cparams = get_final_cparams(processed_results, 'cf')\n",
    "    \n",
    "    # uncomment the ones to run, with correctly chosen hyperparameters\n",
    "    for s in seeds:\n",
    "        CFG['seed'] = s\n",
    "        print(f'running with seed {s}')\n",
    "        \n",
    "        # # ours\n",
    "        opt = optax.inject_hyperparams(optax.sgd)(learning_rate=2e-4)\n",
    "        # opt = optax.inject_hyperparams(optax.adam)(learning_rate=1e-3)\n",
    "        results['cf'].append(train_meta_opt(CFG, counterfactual=True, H=32, HH=2, meta_optimizer=opt))\n",
    "\n",
    "        # standard benchmarks\n",
    "        benchmarks = {\n",
    "            # 'sgd': optax.inject_hyperparams(optax.sgd)(learning_rate=0.4),\n",
    "            # 'momentum': optax.chain(optax.add_decayed_weights(1e-4), optax.inject_hyperparams(optax.sgd)(learning_rate=0.1, momentum=0.9)),\n",
    "            # 'adamw': optax.inject_hyperparams(optax.adamw)(learning_rate=1e-3, b1=0.9, b2=0.999, weight_decay=1e-4),\n",
    "            # 'rmsprop': optax.inject_hyperparams(optax.rmsprop)(learning_rate=1e-3),\n",
    "            # 'rsqrt': rsqrt(lr=0.004, warmup_steps=4000),\n",
    "        }\n",
    "        for k, opt in benchmarks.items(): results[k].append(train_standard_opt(CFG, opt))\n",
    "\n",
    "        # other\n",
    "        # results['hgd'].append(train_hgd(CFG, initial_lr=0.1, hypergrad_lr=1e-3))\n",
    "\n",
    "        save_checkpoint(CFG, results, checkpoint_name=f'seed {s}')\n",
    "    processed_results = process_results(CFG, results)\n",
    "# =================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd628584-11b8-4421-93a5-1d9b936b1f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \u001b[93m\u001b[1mcpu\u001b[0m for jax\n",
      "results will be stored at: \u001b[96m\u001b[1m/Users/evandigiorno/Desktop/meta-opt/notebooks/../data/ncq_pretrained_*.pkl\u001b[0m\n",
      "we will \u001b[91m\u001b[1mNOT\u001b[0m try to load experiment checkpoint first\n",
      "\u001b[91m\u001b[1mWARNING: there already exists a checkpoint with this name! make sure you want to overwrite\u001b[0m\n",
      "starting the experiment from scratch :)\n",
      "running with seed 7\n",
      "64 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 520.75it/s, loss=-5.47, eval_loss=-5.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 649.01it/s, loss=-5.51, eval_loss=-5.51, lr=0.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 643.43it/s, loss=-5.5, eval_loss=-5.5, lr=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 params in the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 625.78it/s, loss=-4.18, eval_loss=-4.18, lr=0.001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mSaved checkpoint seed 7 to /Users/evandigiorno/Desktop/meta-opt/notebooks/../data/ncq_pretrained_raw.pkl\u001b[0m\n",
      "\u001b[92m\u001b[1mSaved processed results to /Users/evandigiorno/Desktop/meta-opt/notebooks/../data/ncq_pretrained_processed.pkl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "run(SEEDS, CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b647b-3c9c-4805-b56e-7ea1587e9adf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-opt",
   "language": "python",
   "name": "meta-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
