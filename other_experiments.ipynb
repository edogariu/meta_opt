{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d902f-6c49-4270-a7d2-ca44be9503f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for use in google colab!!\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !pip install ./meta-opt\n",
    "# !pip install tensorflow-text ml_collections clu sentencepiece  # for WMT\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DIR_PREFIX = \"drive/My Drive/meta-opt\"\n",
    "\n",
    "# # for extra one-time setup in colab\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !mkdir meta-opt/data\n",
    "# !mkdir meta-opt/datasets\n",
    "# !cp -r \"meta-opt\" \"drive/My Drive/\"\n",
    "# !pip install kora -q  # library from https://stackoverflow.com/questions/62596466/how-can-i-run-notebooks-of-a-github-project-in-google-colab to help get ID\n",
    "# from kora.xattr import get_id\n",
    "# fid = get_id(f\"{dir_prefix}meta_opt.ipynb\")\n",
    "# print(\"https://colab.research.google.com/drive/\"+fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f07326-a164-4e44-8a3f-13aa6770c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from meta_opt.nn.trainer import create_train_state, gradient_descent, reset_model, eval\n",
    "from meta_opt.problems import mnist, cifar10, wmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c135c0c-f5db-42cb-b2a5-3833ad98b29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    if seed is None: \n",
    "        seed = np.random.randint()\n",
    "        print('seed set to {}'.format(seed))\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    return rng, seed\n",
    "\n",
    "def get_problem(seed, name, optimizer):\n",
    "    rng, seed = set_seed(seed)\n",
    "    init_rng, rng = jax.random.split(rng)\n",
    "\n",
    "    # get dataset and model\n",
    "    if 'MNIST' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = mnist.load_mnist(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = mnist.MLP([28 * 28, 100, 100, 10])\n",
    "    elif 'CIFAR' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = cifar10.load_cifar10(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = cifar10.VGG(stages=((32, 32), (64, 64), (128, 128)), layer_dims=[128, 10], drop_last_activation=True, dropout=0.1)\n",
    "    elif 'WMT' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = wmt.load_wmt(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = wmt.make_transformer(num_heads=8, num_layers=6, emb_dim=256, qkv_dim=256, mlp_dim=1024)\n",
    "    else:\n",
    "        raise NotImplementedError(name)\n",
    "\n",
    "    tstate = create_train_state(init_rng, model, example_input, optimizer, loss_fn, acc_fn=acc_fn)\n",
    "    del init_rng\n",
    "\n",
    "    args = {'seed': seed,\n",
    "            'model': str(model),\n",
    "            'params': sum(x.size for x in jax.tree_util.tree_leaves(tstate.params)),\n",
    "            'dataset': name,\n",
    "            'num_iters': NUM_ITERS,\n",
    "            'eval_every': EVAL_EVERY,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'reset_every': RESET_EVERY,\n",
    "            'print_every': PRINT_EVERY}\n",
    "\n",
    "    return tstate, train_ds, test_ds, rng, args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5fcbf6-eda5-4006-a31a-16e0f2cecc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_standard_opt(seed, problem_name, optimizer):\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "    \n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = deepcopy(tstate.opt_state.hyperparams)\n",
    "    args['optimizer_args']['name'] = 'standard'\n",
    "    stats['args'] = args\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        stats[t] = s\n",
    "    \n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    return dict(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-opt",
   "language": "python",
   "name": "meta-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
