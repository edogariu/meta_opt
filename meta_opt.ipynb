{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760f4e7d-a02f-42f3-b87d-231d03392428",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "760f4e7d-a02f-42f3-b87d-231d03392428",
    "outputId": "a2cd2bc1-b9e4-4806-d2e5-3dfeb902743c"
   },
   "outputs": [],
   "source": [
    "# # for use in google colab!!\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !pip install ./meta-opt\n",
    "# !pip install tensorflow-text ml_collections clu sentencepiece  # for WMT\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DIR_PREFIX = \"drive/My Drive/meta-opt\"\n",
    "\n",
    "# # for extra one-time setup in colab\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !mkdir meta-opt/data\n",
    "# !mkdir meta-opt/datasets\n",
    "# !cp -r \"meta-opt\" \"drive/My Drive/\"\n",
    "# !pip install kora -q  # library from https://stackoverflow.com/questions/62596466/how-can-i-run-notebooks-of-a-github-project-in-google-colab to help get ID\n",
    "# from kora.xattr import get_id\n",
    "# fid = get_id(f\"{dir_prefix}meta_opt.ipynb\")\n",
    "# print(\"https://colab.research.google.com/drive/\"+fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b898f1e-f002-435a-b1b4-65a21e05a8a7",
   "metadata": {
    "id": "7b898f1e-f002-435a-b1b4-65a21e05a8a7"
   },
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from meta_opt.nn.trainer import create_train_state, gradient_descent, reset_model, eval\n",
    "from meta_opt.problems import mnist, cifar10, wmt\n",
    "\n",
    "from meta_opt.meta_opt import MetaOpt\n",
    "from meta_opt.gaps import MetaOptGAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730ed64-63a1-46de-8106-28529a15467e",
   "metadata": {
    "id": "6730ed64-63a1-46de-8106-28529a15467e"
   },
   "source": [
    "### Todo\n",
    "- add caching to dataloaders\n",
    "- add MP, cosine, cyclical learning rates, hedging, AGD, DoWG, D-adaptation, adagrad & rmsprop\n",
    "- try other settings\n",
    "- check \"training instability\" literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56168648-67e9-4ee2-91b8-38dfe7ae5f12",
   "metadata": {
    "id": "56168648-67e9-4ee2-91b8-38dfe7ae5f12"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    if seed is None:\n",
    "        seed = np.random.randint()\n",
    "        print('seed set to {}'.format(seed))\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    return rng, seed\n",
    "\n",
    "def get_problem(seed, name, optimizer):\n",
    "    rng, seed = set_seed(seed)\n",
    "    init_rng, rng = jax.random.split(rng)\n",
    "\n",
    "    # get dataset and model\n",
    "    if 'MNIST' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = mnist.load_mnist(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = mnist.MLP([28 * 28, 100, 100, 10])\n",
    "    elif 'CIFAR' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = cifar10.load_cifar10(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = cifar10.VGG(stages=((32, 32), (64, 64), (128, 128)), layer_dims=[128, 10], drop_last_activation=True, dropout=0.1)\n",
    "    elif 'WMT' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn, tokenizer = wmt.load_wmt(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets', num_eval_iters=NUM_EVAL_ITERS if 'NUM_EVAL_ITERS' in globals() else 256)\n",
    "        train_ds.cache()\n",
    "        model = wmt.make_transformer(num_heads=8, num_layers=6, emb_dim=256, qkv_dim=256, mlp_dim=1024)\n",
    "    else:\n",
    "        raise NotImplementedError(name)\n",
    "\n",
    "    tstate = create_train_state(init_rng, model, example_input, optimizer, loss_fn, acc_fn=acc_fn)\n",
    "    del init_rng\n",
    "\n",
    "    args = {'seed': seed,\n",
    "            'model': str(model),\n",
    "            'params': sum(x.size for x in jax.tree_util.tree_leaves(tstate.params)),\n",
    "            'dataset': name,\n",
    "            'num_iters': NUM_ITERS,\n",
    "            'eval_every': EVAL_EVERY,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'reset_every': RESET_EVERY,\n",
    "            'print_every': PRINT_EVERY}\n",
    "    if 'WMT' in name: args['tokenizer'] = tokenizer\n",
    "\n",
    "    return tstate, train_ds, test_ds, rng, args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68611b25-ff6c-498a-bac1-30873eac9b16",
   "metadata": {
    "id": "68611b25-ff6c-498a-bac1-30873eac9b16"
   },
   "source": [
    "# Standard Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35553ddc-66dd-454e-9608-8820ba402b03",
   "metadata": {
    "id": "35553ddc-66dd-454e-9608-8820ba402b03"
   },
   "outputs": [],
   "source": [
    "def train_standard_opt(seed, problem_name, optimizer):\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "\n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = deepcopy(tstate.opt_state.hyperparams)\n",
    "    args['optimizer_args']['name'] = 'standard'\n",
    "    stats['args'] = args\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "\n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "\n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0:\n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    stats['model_params'] = deepcopy(tstate.params)\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d2163-9b72-4c54-85cc-2abb68c0459f",
   "metadata": {
    "id": "5b4d2163-9b72-4c54-85cc-2abb68c0459f"
   },
   "source": [
    "# Meta-Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907792cd-7420-4e61-a458-372e2dac9128",
   "metadata": {
    "id": "907792cd-7420-4e61-a458-372e2dac9128"
   },
   "outputs": [],
   "source": [
    "def train_meta_opt(seed, problem_name: str, m_method: str, meta_lr: float, use_adam: bool, H: int, HH: int, initial_lr: int):\n",
    "    optimizer = optax.sgd(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "\n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'meta',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'm_method': m_method,\n",
    "                              'meta_lr': meta_lr,\n",
    "                              'use_adam': use_adam,\n",
    "                              'H': H,\n",
    "                              'HH': HH\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "    meta_opt = MetaOpt(tstate, H=H, HH=HH, meta_lr=meta_lr, delta=1e-5, m_method=m_method, use_adam=use_adam)\n",
    "\n",
    "    it = iter(train_ds.as_numpy_iterator())\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "\n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            meta_opt = meta_opt.episode_reset()\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        tstate = meta_opt.meta_step(tstate, grads, batch)\n",
    "\n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0:\n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        if m_method == 'scalar': s['M'] = meta_opt.cstate.M.reshape(-1)\n",
    "        else: s['M'] = jnp.stack([m.reshape((m.shape[0], -1)).mean(axis=-1) for m in jax.tree_util.tree_leaves(meta_opt.cstate.M)], axis=0).mean(axis=0)\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3), 'M': s['M'].sum()})\n",
    "\n",
    "    stats['model_params'] = deepcopy(tstate.params)\n",
    "    stats['controller_params'] = deepcopy(meta_opt.cstate.M)\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10045c-53d9-41f3-b559-f7a0c2fe8bf6",
   "metadata": {
    "id": "4d10045c-53d9-41f3-b559-f7a0c2fe8bf6"
   },
   "source": [
    "# Gradient-based Adaptive Policy Selection (GAPS) Meta-Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5867db6-fe41-4dbd-9934-1a52617cc94c",
   "metadata": {
    "id": "c5867db6-fe41-4dbd-9934-1a52617cc94c"
   },
   "outputs": [],
   "source": [
    "def train_gaps_meta_opt(seed, problem_name: str, m_method: str, meta_lr: float, use_adam: bool, H: int, B: int, initial_lr: int):\n",
    "    optimizer = optax.sgd(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "\n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'gaps_meta',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'm_method': m_method,\n",
    "                              'meta_lr': meta_lr,\n",
    "                              'use_adam': use_adam,\n",
    "                              'H': H,\n",
    "                              'B': B\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "\n",
    "    meta_opt = MetaOptGAPS(tstate, H=H, B=B, meta_lr=meta_lr, use_adam=use_adam, delta=1e-5, m_method=m_method)\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "\n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            meta_opt = meta_opt.episode_reset()\n",
    "            del reset_rng\n",
    "\n",
    "        # tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        tstate, (loss, grads) = meta_opt.meta_step(tstate, batch)\n",
    "\n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0:\n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        if m_method == 'scalar': s['M'] = meta_opt.cstate.M.reshape(-1)\n",
    "        else: s['M'] = jnp.stack([m.reshape((m.shape[0], -1)).mean(axis=-1) for m in jax.tree_util.tree_leaves(meta_opt.cstate.M)], axis=0).mean(axis=0)\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3), 'M': s['M'].sum()})\n",
    "\n",
    "    stats['model_params'] = deepcopy(tstate.params)\n",
    "    stats['controller_params'] = deepcopy(meta_opt.cstate.M)\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada709b3-489a-44e8-bba2-cfd9221f0988",
   "metadata": {
    "id": "ada709b3-489a-44e8-bba2-cfd9221f0988"
   },
   "source": [
    "# Hypergradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5f5747-f1ee-43fb-8e9e-5228dd1b3bd3",
   "metadata": {
    "id": "bb5f5747-f1ee-43fb-8e9e-5228dd1b3bd3"
   },
   "outputs": [],
   "source": [
    "def train_hgd(seed, problem_name: str, initial_lr: float, hypergrad_lr: float):\n",
    "\n",
    "    optimizer = optax.inject_hyperparams(optax.sgd)(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "\n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'hgd',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'hypergrad_lr': hypergrad_lr,\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "\n",
    "    prev_grads = None\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "\n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        if prev_grads is not None:\n",
    "            hypergrad = -sum([(g1 * g2).sum() for g1, g2 in zip(jax.tree_util.tree_leaves(grads), jax.tree_util.tree_leaves(prev_grads))])\n",
    "            tstate.opt_state.hyperparams['learning_rate'] -= hypergrad_lr * hypergrad\n",
    "        prev_grads = grads\n",
    "\n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        s['lr'] = tstate.opt_state.hyperparams['learning_rate'].item()\n",
    "        if t % EVAL_EVERY == 0:\n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    stats['model_params'] = deepcopy(tstate.params)\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125998da-b7ed-4d07-af09-d2020a813e0a",
   "metadata": {
    "id": "125998da-b7ed-4d07-af09-d2020a813e0a"
   },
   "source": [
    "# Run\n",
    "Select the hyperparameters and the seeds to use for each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8211e988-2b8f-43a1-9ba5-23045d3057d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8211e988-2b8f-43a1-9ba5-23045d3057d3",
    "outputId": "6d600c8b-fbed-4554-ae1d-9688244e5633"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: WMT_1-13\n",
      "using cpu for jax\n",
      "saving data at `./data/`\n"
     ]
    }
   ],
   "source": [
    "# hyperparams\n",
    "SEEDS = [48,]\n",
    "# SEEDS = [62, 23, 37]\n",
    "# SEEDS = [48, 62, 23, 37]\n",
    "NUM_ITERS = 8000\n",
    "EVAL_EVERY = 8000\n",
    "BATCH_SIZE = 32\n",
    "RESET_EVERY = 8000\n",
    "PRINT_EVERY = int(1e10)\n",
    "\n",
    "NAME = 'WMT_1-13'\n",
    "if 'DIR_PREFIX' not in globals(): DIR_PREFIX = '.'  # use this directory if unspecified\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print('dataset:', NAME)\n",
    "print('using', xla_bridge.get_backend().platform, 'for jax')\n",
    "print(f'saving data at `{DIR_PREFIX}/data/`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f4b5b25-2f17-4c6a-afaa-88f904c1c98e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0f4b5b25-2f17-4c6a-afaa-88f904c1c98e",
    "outputId": "57877e06-c805-47db-ad58-13d0acdffe89"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# uncomment the ones to run\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# results = defaultdict(list)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# filename = f'{DIR_PREFIX}/data/{NAME}_raw.pkl'; results = pkl.load(open(filename, 'rb')); print(f'loaded checkpoint from {filename}')\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m SEEDS:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# standard benchmarks\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# results['sgd_0.1'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.1)))  # (CIFAR, 0.1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# results['scalar_0.00004'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.00004, H=64, HH=2, initial_lr=0.01, use_adam=False))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# results['scalar_adam_0.0001'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.0001, H=24, HH=2, initial_lr=0.01, use_adam=True))  # (CIFAR, <=0.0001)\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mresults\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar_adam_0.0004\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_meta_opt(s, NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscalar\u001b[39m\u001b[38;5;124m'\u001b[39m, meta_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0004\u001b[39m, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m24\u001b[39m, HH\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, initial_lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, use_adam\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# diagonal\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# results['diagonal_1.0'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=1.0, H=36, HH=2, initial_lr=0.01, use_adam=False))\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# results['diagonal_adam_0.0002'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=0.0002, H=36, HH=2, initial_lr=0.01, use_adam=True))\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# # the caltech paper\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# results['meta_GAPS'].append(train_gaps_meta_opt(s, NAME, 'scalar', meta_lr=0.001, H=6, B=6, initial_lr=0.2, use_adam=False))\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
     ]
    }
   ],
   "source": [
    "# uncomment the ones to run\n",
    "# results = defaultdict(list)\n",
    "# filename = f'{DIR_PREFIX}/data/{NAME}_raw.pkl'; results = pkl.load(open(filename, 'rb')); print(f'loaded checkpoint from {filename}')\n",
    "\n",
    "for s in SEEDS:\n",
    "    # standard benchmarks\n",
    "    # results['sgd_0.1'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.1)))  # (CIFAR, 0.1)\n",
    "    # results['sgd_0.04'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.04)))\n",
    "    # results['sgd_0.4'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.4)))\n",
    "    # results['momentum_0.01'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.01, momentum=0.9)))  # (CIFAR, 0.01)\n",
    "    # results['momentum_0.001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.001, momentum=0.9)))\n",
    "    # results['adam_0.001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=1e-3)))  # (CIFAR, 0.001)\n",
    "    # results['adam_0.0001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=1e-4)))\n",
    "    # results['rmsprop_0.001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.rmsprop)(learning_rate=0.001)))  # (CIFAR, 0.001)\n",
    "    # results['hgd_0.1'].append(train_hgd(s, NAME, initial_lr=0.1, hypergrad_lr=1e-5))\n",
    "\n",
    "    # scalar\n",
    "    # results['scalar_0.001'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.001, H=32, HH=2, initial_lr=0.01, use_adam=False))\n",
    "    # results['scalar_0.00004'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.00004, H=64, HH=2, initial_lr=0.01, use_adam=False))\n",
    "    # results['scalar_adam_0.0001'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.0001, H=24, HH=2, initial_lr=0.01, use_adam=True))  # (CIFAR, <=0.0001)\n",
    "    results['scalar_adam_0.0004'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.0004, H=24, HH=2, initial_lr=0.01, use_adam=True))\n",
    "\n",
    "    # diagonal\n",
    "    # results['diagonal_1.0'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=1.0, H=36, HH=2, initial_lr=0.01, use_adam=False))\n",
    "    # results['diagonal_adam_0.0002'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=0.0002, H=36, HH=2, initial_lr=0.01, use_adam=True))\n",
    "\n",
    "    # # the caltech paper\n",
    "    # results['meta_GAPS'].append(train_gaps_meta_opt(s, NAME, 'scalar', meta_lr=0.001, H=6, B=6, initial_lr=0.2, use_adam=False))\n",
    "\n",
    "    if len(results) > 0:\n",
    "        filename = f'{DIR_PREFIX}/data/{NAME}_raw.pkl'\n",
    "        with open(filename, 'wb') as f:\n",
    "            pkl.dump(results, f)\n",
    "            print(f'Saved checkpoint for seed #{s} to {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f1b24-5846-45f3-b20b-ddcd89bf8fe5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "335f1b24-5846-45f3-b20b-ddcd89bf8fe5",
    "outputId": "2ffe56e0-b788-4f42-d308-c44d06a83db4"
   },
   "outputs": [],
   "source": [
    "# clean the stats\n",
    "to_del = []\n",
    "for k, v in results.items():\n",
    "    if len(v) == 0: to_del.append(k)\n",
    "for k in to_del: del results[k]\n",
    "\n",
    "aggregated = {}  # experiment name -> 'args' or timestamp -> stat key -> stat value\n",
    "# gather stats\n",
    "for k, v in results.items():  # for each experiment\n",
    "    aggregated[k] = {'args': []}\n",
    "\n",
    "    for n in range(len(v)):  # for each trial\n",
    "        aggregated[k]['args'].append(v[n]['args'])\n",
    "\n",
    "        for t in range(1, v[0]['args']['num_iters'] + 1):  # for each timestamp\n",
    "            for stat_key, value in v[n][t].items():  # for each stat recorded at that timestamp\n",
    "                if stat_key not in aggregated[k]: aggregated[k][stat_key] = {}\n",
    "                if t not in aggregated[k][stat_key]: aggregated[k][stat_key][t] = []\n",
    "                aggregated[k][stat_key][t].append(value)\n",
    "\n",
    "# aggregate stats\n",
    "ret = defaultdict(dict)  # stat key -> experiment name -> 't' or 'avg' or 'std' ->\n",
    "args = {}\n",
    "for k, v in aggregated.items():  # for experiment\n",
    "    for stat_key in v.keys():  # for stat\n",
    "        if stat_key == 'args':\n",
    "            args[k] = v[stat_key]\n",
    "            continue\n",
    "        if k not in ret[stat_key]: ret[stat_key][k] = {}\n",
    "        ret[stat_key][k]['t'] = list(v[stat_key].keys())\n",
    "        arr = np.array(list(v[stat_key].values()))\n",
    "        ret[stat_key][k]['avg'] = np.mean(arr, axis=1)\n",
    "        ret[stat_key][k]['std'] = np.std(arr, axis=1)\n",
    "\n",
    "with open(f'{DIR_PREFIX}/data/{NAME}_processed.pkl', 'wb') as f:\n",
    "    pkl.dump(ret, f)\n",
    "    print('Saved processed results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13ef9-3e01-4171-b516-a50e90c4c8cf",
   "metadata": {
    "id": "c3f13ef9-3e01-4171-b516-a50e90c4c8cf"
   },
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kkj0hJUA5gkp",
   "metadata": {
    "id": "kkj0hJUA5gkp"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# plot a particular set of experiments\n",
    "# ----------------------------------------\n",
    "# keys_to_plot = [\n",
    "#     'sgd_0.1',\n",
    "#     'momentum_0.01',\n",
    "#     'adam_0.001',\n",
    "#     'rmsprop_0.001',\n",
    "#     'scalar_adam_0.0001',\n",
    "#     'scalar_adam_0.00004',\n",
    "#     ]\n",
    "\n",
    "# ----------------------------------------\n",
    "# OR just plot em all\n",
    "# ----------------------------------------\n",
    "keys_to_plot = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6db68-9bdc-41cc-95eb-ebdfe55807fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "93d6db68-9bdc-41cc-95eb-ebdfe55807fd",
    "outputId": "bdf7617b-bac0-49ea-f3ba-25b6227fb01c"
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(len(ret), 1, figsize=(10, 24))\n",
    "\n",
    "for i, stat_key in enumerate(ret.keys()):\n",
    "    ax[i].set_title(stat_key)\n",
    "    for experiment_name in ret[stat_key].keys():\n",
    "        if keys_to_plot is not None and experiment_name not in keys_to_plot: continue\n",
    "        ts, avgs, stds = ret[stat_key][experiment_name]['t'], ret[stat_key][experiment_name]['avg'], ret[stat_key][experiment_name]['std']\n",
    "        if avgs.ndim == 2:\n",
    "            ax[i].plot(ts, avgs.mean(axis=-1), label=experiment_name)\n",
    "            ax[i].fill_between(ts, avgs.mean(axis=-1) - 1.96 * stds.mean(axis=-1), avgs.mean(axis=-1) + 1.96 * stds.mean(axis=-1), alpha=0.2)\n",
    "            # for j in range(avgs.shape[1]):\n",
    "            #     ax[i].plot(ts, avgs[:, j], label=f'{experiment_name} {str(j)}')\n",
    "            #     ax[i].fill_between(ts, avgs[:, j] - 1.96 * stds[:, j], avgs[:, j] + 1.96 * stds[:, j], alpha=0.2)\n",
    "        else:\n",
    "            if stat_key in ['loss', 'grad_sq_norm']:\n",
    "                n = 20\n",
    "                kernel = np.array([1 / n,] * n)\n",
    "                avgs = np.convolve(avgs, kernel)[n // 2:n // 2 + avgs.shape[0]]\n",
    "                stds = np.convolve(stds ** 2, kernel ** 2)[n // 2:n // 2 + stds.shape[0]] ** 0.5\n",
    "            ax[i].plot(ts, avgs, label=experiment_name)\n",
    "            ax[i].fill_between(ts, avgs - 1.96 * stds, avgs + 1.96 * stds, alpha=0.2)\n",
    "    ax[i].legend()\n",
    "\n",
    "\n",
    "# ax[1].set_ylim(-0.1, 2.5)\n",
    "# ax[2].set_ylim(-0.1, 0.7)\n",
    "# ax[3].set_ylim(0.85, 1.02)\n",
    "# ax[4].set_ylim(-0.1, 40)\n",
    "# ax[5].set_ylim(-0.05, 0.05)\n",
    "# plt.savefig(f'{DIR_PREFIX}/figs/{NAME}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba19d7-3966-4d47-9bda-ce1d56709cd4",
   "metadata": {
    "id": "0dba19d7-3966-4d47-9bda-ce1d56709cd4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ba532d-68c3-44f3-809c-13cfade2d1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint from ./data/WMT_1-13_raw.pkl\n"
     ]
    }
   ],
   "source": [
    "filename = f'{DIR_PREFIX}/data/{NAME}_raw.pkl'; results = pkl.load(open(filename, 'rb')); print(f'loaded checkpoint from {filename}')\n",
    "BATCH_SIZE = 1\n",
    "NUM_EVAL_ITERS = 1\n",
    "tstate, train_ds, test_ds, rng, args = get_problem(seed=0, name=NAME, optimizer=optax.sgd(0.1))\n",
    "tstate = tstate.replace(params=results['sgd_0.1'][0]['model_parameters'])\n",
    "# meta_opt = MetaOpt(tstate, H=24, HH=2, meta_lr=1e-4, delta=1e-5, m_method='scalar', use_adam=True)\n",
    "\n",
    "# # evaluate\n",
    "# n = 0\n",
    "# loss, acc = 0., 0.\n",
    "# for batch in tqdm.tqdm(test_ds.as_numpy_iterator()):\n",
    "#     l, a = eval(tstate, batch)\n",
    "#     loss += l; acc += a\n",
    "#     n += 1\n",
    "#     print(l, a)\n",
    "# loss /= n; acc /= n\n",
    "# print(loss, acc, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c08b1b3e-0b54-42af-b7ec-a513dfae8a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0]]\n",
      "Ursprünglich war die Schulhofsanierung sogar schon in den Jahren 2008/2009 geplant, doch hohe unplanmäßige Ausgaben brachten eine Verschiebung.\n",
      "\n",
      "The school yard renovation was originally planned back in 2008/2009, however, high unplanned expenses meant that the work had to be pushed back.\n",
      "\n",
      " ⁇ \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from meta_opt.problems._bleu import predict_step, bleu_partial, complete_bleu, per_host_sum_pmap, EOS_ID\n",
    "\n",
    "def translate_and_calculate_bleu(\n",
    "    tstate,\n",
    "    dataset,\n",
    "    tokenizer,\n",
    "    max_predict_length: int = 256,\n",
    "):\n",
    "  \"\"\"Translates the `dataset` and calculates the BLEU score.\"\"\"\n",
    "\n",
    "  def decode_tokens(toks):\n",
    "    valid_toks = toks[: np.argmax(toks == EOS_ID) + 1].astype(np.int32)\n",
    "    return tokenizer.detokenize(valid_toks).numpy().decode(\"utf-8\")\n",
    "  \n",
    "  sources, references, predictions = [], [], []\n",
    "  for batch in tqdm.tqdm(dataset):\n",
    "    pred = predict_step(tstate, batch)\n",
    "    # Iterate through non-padding examples of batch.\n",
    "    inputs, targets = batch['x']['inputs'], batch['y']\n",
    "    for i, s in enumerate(pred):\n",
    "      sources.append(decode_tokens(inputs[i]))\n",
    "      references.append(decode_tokens(targets[i]))\n",
    "      predictions.append(decode_tokens(s))\n",
    "      # print(f\"{sources[i]}\\n\\n{references[i]}\\n\\n{predictions[i]}\\n\\n\")\n",
    "\n",
    "  # Calculate BLEU score for translated eval corpus against reference.\n",
    "  bleu_matches = bleu_partial(references, predictions)\n",
    "  all_bleu_matches = per_host_sum_pmap(bleu_matches)\n",
    "  bleu_score = complete_bleu(*all_bleu_matches)\n",
    "  # Save translation samples for tensorboard.\n",
    "  exemplars = \"\"\n",
    "  for n in np.random.choice(np.arange(len(predictions)), 8):\n",
    "    exemplars += f\"{sources[n]}\\n\\n{references[n]}\\n\\n{predictions[n]}\\n\\n\"\n",
    "  return exemplars, bleu_score\n",
    "\n",
    "e, b = translate_and_calculate_bleu(tstate, test_ds.as_numpy_iterator(), args['tokenizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8094eb9-1ab7-485e-b234-0ac58ac86ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1678344485946208e-09"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "meta-opt",
   "language": "python",
   "name": "meta-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
