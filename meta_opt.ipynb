{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "760f4e7d-a02f-42f3-b87d-231d03392428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prepare the repo\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !mkdir meta-opt/data\n",
    "# !ls -a meta-opt\n",
    "\n",
    "# # get a link to the file\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !cp -r \"meta-opt\" \"drive/My Drive/\"\n",
    "# DIR_PREFIX = \"drive/My Drive/meta-opt\"\n",
    "# # !pip install kora -q  # library from https://stackoverflow.com/questions/62596466/how-can-i-run-notebooks-of-a-github-project-in-google-colab to help get ID\n",
    "# # from kora.xattr import get_id\n",
    "# # fid = get_id(f\"{dir_prefix}meta_opt.ipynb\")\n",
    "# # print(\"https://colab.research.google.com/drive/\"+fid)\n",
    "\n",
    "# # install the package\n",
    "# !pip install ./meta-opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b898f1e-f002-435a-b1b4-65a21e05a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "from meta_opt.training.trainer import create_train_state, gradient_descent, reset_model, forward\n",
    "from meta_opt.training.utils import cross_entropy, mse, MLP, CNN, load_mnist, load_cifar10, VGG\n",
    "\n",
    "from meta_opt.meta_opt import MetaOpt\n",
    "from meta_opt.gaps import MetaOptGAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730ed64-63a1-46de-8106-28529a15467e",
   "metadata": {},
   "source": [
    "### Todo\n",
    "- try everything with disturbances from a step forward too :)\n",
    "- add `accuracy` to statistics each eval round\n",
    "- add MP, cosine, cyclical learning rates, hedging, AGD, DoWG, D-adaptation, adagrad & rmsprop\n",
    "- try other settings\n",
    "- check \"training instability\" literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56168648-67e9-4ee2-91b8-38dfe7ae5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    if seed is None: \n",
    "        seed = np.random.randint()\n",
    "        print('seed set to {}'.format(seed))\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    return rng, seed\n",
    "\n",
    "def get_problem(seed, name, optimizer):\n",
    "    rng, seed = set_seed(seed)\n",
    "    init_rng, rng = jax.random.split(rng)\n",
    "\n",
    "    # get dataset and model\n",
    "    if 'MNIST' in name:\n",
    "        train_ds, test_ds, loss_fn, input_dims = load_mnist(NUM_ITERS, BATCH_SIZE)\n",
    "        model = MLP([28 * 28, 100, 100, 10])\n",
    "    elif 'CIFAR' in name:\n",
    "        train_ds, test_ds, loss_fn, input_dims = load_cifar10(NUM_ITERS, BATCH_SIZE)\n",
    "        # model = CNN(channels=[3, 32, 64, 32], layer_dims=[512, 128, 10], drop_last_activation=False)\n",
    "        model = VGG(stages=((32, 32), (64, 64), (128, 128)), layer_dims=[128, 10], drop_last_activation=True, dropout=0.1)\n",
    "\n",
    "        def acc_fn(yhat, y):\n",
    "            print(yhat.shape, y.shape, yhat[0], y[0])\n",
    "            return jnp.mean(jnp.argmax(yhat, -1) == y)\n",
    "            \n",
    "    else:\n",
    "        raise NotImplementedError(name)\n",
    "\n",
    "    tstate = create_train_state(init_rng, model, input_dims, optimizer, loss_fn)\n",
    "    del init_rng\n",
    "\n",
    "    args = {'seed': seed,\n",
    "            'model': str(model),\n",
    "            'dataset': name,\n",
    "            'num_iters': NUM_ITERS,\n",
    "            'eval_every': EVAL_EVERY,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'reset_every': RESET_EVERY,\n",
    "            'print_every': PRINT_EVERY}\n",
    "\n",
    "    return tstate, train_ds, test_ds, rng, args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68611b25-ff6c-498a-bac1-30873eac9b16",
   "metadata": {},
   "source": [
    "# Standard Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35553ddc-66dd-454e-9608-8820ba402b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_standard_opt(seed, problem_name, optimizer):\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "    \n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = deepcopy(tstate.opt_state.hyperparams)\n",
    "    args['optimizer_args']['name'] = 'standard'\n",
    "    stats['args'] = args\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=len(train_ds))):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = forward(tstate, batch, compute_acc=True)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "            s['eval_loss'] /= sen(test_ds)\n",
    "            s['eval_acc'] /= len(test_ds)\n",
    "        stats[t] = s\n",
    "    \n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d2163-9b72-4c54-85cc-2abb68c0459f",
   "metadata": {},
   "source": [
    "# Meta-Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "907792cd-7420-4e61-a458-372e2dac9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta_opt(seed, problem_name: str, m_method: str, meta_lr: float, use_adam: bool, H: int, HH: int, initial_lr: int):\n",
    "    optimizer = optax.sgd(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "    \n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'meta',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'm_method': m_method,\n",
    "                              'meta_lr': meta_lr,\n",
    "                              'use_adam': use_adam,\n",
    "                              'H': H,\n",
    "                              'HH': HH\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "    meta_opt = MetaOpt(tstate, H=H, HH=HH, meta_lr=meta_lr, delta=1e-5, m_method=m_method, use_adam=use_adam)\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=len(train_ds))):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            meta_opt = meta_opt.episode_reset()\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        tstate = meta_opt.meta_step(tstate, grads, batch)\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = forward(tstate, batch, compute_acc=True)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "            s['eval_loss'] /= sen(test_ds)\n",
    "            s['eval_acc'] /= len(test_ds)\n",
    "        if m_method == 'scalar': s['M'] = meta_opt.cstate.M.reshape(-1)\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10045c-53d9-41f3-b559-f7a0c2fe8bf6",
   "metadata": {},
   "source": [
    "# Gradient-based Adaptive Policy Selection (GAPS) Meta-Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5867db6-fe41-4dbd-9934-1a52617cc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gaps_meta_opt(seed, problem_name: str, m_method: str, meta_lr: float, use_adam: bool, H: int, B: int, initial_lr: int):\n",
    "    optimizer = optax.sgd(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "    \n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'gaps_meta',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'm_method': m_method,\n",
    "                              'meta_lr': meta_lr,\n",
    "                              'use_adam': use_adam,\n",
    "                              'H': H,\n",
    "                              'B': B\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "\n",
    "    meta_opt = MetaOptGAPS(tstate, H=H, B=B, meta_lr=meta_lr, use_adam=use_adam, delta=1e-5, m_method=m_method)\n",
    "    \n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=len(train_ds))):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            meta_opt = meta_opt.episode_reset()\n",
    "            del reset_rng\n",
    "\n",
    "        # tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        tstate, (loss, grads) = meta_opt.meta_step(tstate, batch)\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = forward(tstate, batch, compute_acc=True)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "            s['eval_loss'] /= sen(test_ds)\n",
    "            s['eval_acc'] /= len(test_ds)\n",
    "        if m_method == 'scalar': s['M'] = meta_opt.cstate.M.reshape(-1)\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada709b3-489a-44e8-bba2-cfd9221f0988",
   "metadata": {},
   "source": [
    "# Hypergradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb5f5747-f1ee-43fb-8e9e-5228dd1b3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hgd(seed, problem_name: str, initial_lr: float, hypergrad_lr: float):\n",
    "\n",
    "    optimizer = optax.inject_hyperparams(optax.sgd)(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "\n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'hgd',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'hypergrad_lr': hypergrad_lr,\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "    \n",
    "    prev_grads = None\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=len(train_ds))):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        if prev_grads is not None: \n",
    "            hypergrad = -sum([(g1 * g2).sum() for g1, g2 in zip(jax.tree_util.tree_leaves(grads), jax.tree_util.tree_leaves(prev_grads))])\n",
    "            tstate.opt_state.hyperparams['learning_rate'] -= hypergrad_lr * hypergrad\n",
    "        prev_grads = grads\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        s['lr'] = tstate.opt_state.hyperparams['learning_rate'].item()\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = forward(tstate, batch, compute_acc=True)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "            s['eval_loss'] /= sen(test_ds)\n",
    "            s['eval_acc'] /= len(test_ds)\n",
    "        stats[t] = s\n",
    "    \n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125998da-b7ed-4d07-af09-d2020a813e0a",
   "metadata": {},
   "source": [
    "# Run\n",
    "Select the hyperparameters and the seeds to use for each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8211e988-2b8f-43a1-9ba5-23045d3057d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: CIFAR\n",
      "using cpu for jax\n",
      "saving data at `./data/`\n"
     ]
    }
   ],
   "source": [
    "# hyperparams\n",
    "SEEDS = [18, 29, 69, 1] \n",
    "NUM_ITERS = 25000\n",
    "EVAL_EVERY = 100\n",
    "BATCH_SIZE = 512\n",
    "RESET_EVERY = 5000\n",
    "PRINT_EVERY = int(1e10)\n",
    "\n",
    "NAME = 'CIFAR'\n",
    "if 'DIR_PREFIX' not in globals(): DIR_PREFIX = '.'  # use this directory if unspecified\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print('dataset:', NAME)\n",
    "print('using', xla_bridge.get_backend().platform, 'for jax')\n",
    "print(f'saving data at `{DIR_PREFIX}/data/`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6789cb07-84fd-468d-a29e-b0f5a15c59fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                             | 18/25000 [00:20<7:50:40,  1.13s/it, loss=2.27]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# results = pkl.load(open(f'{DIR_PREFIX}/data/{NAME}_raw.pkl', 'rb'))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m SEEDS:\n\u001b[0;32m----> 6\u001b[0m     results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msgd\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_standard_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minject_hyperparams\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msgd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     results['adam'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=0.001)))\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     results['adam_0.0001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=1e-4)))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     results['adam_0.0005'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=5e-4)))\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#     results['meta_GAPS'].append(train_gaps_meta_opt(s, NAME, 'scalar', meta_lr=0.005, H=6, B=6, initial_lr=0.2))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#     results['hgd'].append(train_hgd(s, NAME, initial_lr=0.4, hypergrad_lr=1e-4)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDIR_PREFIX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mNAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_raw.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: \n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mtrain_standard_opt\u001b[0;34m(seed, problem_name, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m     tstate \u001b[38;5;241m=\u001b[39m reset_model(reset_rng, tstate)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m reset_rng\n\u001b[0;32m---> 18\u001b[0m tstate, (loss, grads) \u001b[38;5;241m=\u001b[39m \u001b[43mgradient_descent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# update all the stats\u001b[39;00m\n\u001b[1;32m     21\u001b[0m s \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# uncomment the ones to run\n",
    "results = defaultdict(list)\n",
    "# results = pkl.load(open(f'{DIR_PREFIX}/data/{NAME}_raw.pkl', 'rb'))\n",
    "\n",
    "for s in SEEDS:\n",
    "    results['sgd'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.2)))\n",
    "#     results['adam'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=0.001)))\n",
    "#     results['adam_0.0001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=1e-4)))\n",
    "#     results['adam_0.0005'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=5e-4)))\n",
    "#     results['meta_scalar'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.008, H=4, HH=2, initial_lr=0.1, use_adam=False))\n",
    "    # results['meta_scalar_long2'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.006, H=10, HH=4, initial_lr=0.1, use_adam=False))\n",
    "#     results['meta_scalar_adam'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.001, H=4, HH=2, initial_lr=0.1, use_adam=True))\n",
    "#     results['meta_diagonal'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=1e-1, H=4, HH=2, initial_lr=0.2))\n",
    "#     results['meta_GAPS'].append(train_gaps_meta_opt(s, NAME, 'scalar', meta_lr=0.005, H=6, B=6, initial_lr=0.2))\n",
    "#     results['hgd'].append(train_hgd(s, NAME, initial_lr=0.4, hypergrad_lr=1e-4)\n",
    "    \n",
    "    with open(f'{DIR_PREFIX}/data/{NAME}_raw.pkl', 'wb') as f: \n",
    "        pkl.dump(results, f)\n",
    "        print(f'Saved checkpoint for seed #{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f1b24-5846-45f3-b20b-ddcd89bf8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the stats\n",
    "aggregated = {}  # experiment name -> 'args' or timestamp -> stat key -> stat value\n",
    "# gather stats\n",
    "for k, v in results.items():  # for each experiment\n",
    "    aggregated[k] = {'args': []}\n",
    "\n",
    "    for n in range(len(SEEDS)):  # for each trial\n",
    "        aggregated[k]['args'].append(v[n]['args'])\n",
    "        \n",
    "        for t in range(1, v[0]['args']['num_iters'] + 1):  # for each timestamp    \n",
    "            for stat_key, value in v[n][t].items():  # for each stat recorded at that timestamp\n",
    "                if stat_key not in aggregated[k]: aggregated[k][stat_key] = {}\n",
    "                if t not in aggregated[k][stat_key]: aggregated[k][stat_key][t] = []\n",
    "                aggregated[k][stat_key][t].append(value)\n",
    "\n",
    "# aggregate stats\n",
    "ret = defaultdict(dict)  # stat key -> experiment name -> 't' or 'avg' or 'std' -> \n",
    "args = {}\n",
    "for k, v in aggregated.items():  # for experiment\n",
    "    for stat_key in v.keys():  # for stat \n",
    "        if stat_key == 'args': \n",
    "            args[k] = v[stat_key]\n",
    "            continue\n",
    "        if k not in ret[stat_key]: ret[stat_key][k] = {}\n",
    "        ret[stat_key][k]['t'] = list(v[stat_key].keys())\n",
    "        arr = np.array(list(v[stat_key].values()))\n",
    "        ret[stat_key][k]['avg'] = np.mean(arr, axis=1)\n",
    "        ret[stat_key][k]['std'] = np.std(arr, axis=1)\n",
    "\n",
    "with open(f'{DIR_PREFIX}/data/{NAME}_processed.pkl', 'wb') as f: \n",
    "    pkl.dump(ret, f)\n",
    "    print('Saved processed results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13ef9-3e01-4171-b516-a50e90c4c8cf",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6db68-9bdc-41cc-95eb-ebdfe55807fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(len(ret), 1, figsize=(10, 24))\n",
    "\n",
    "for i, stat_key in enumerate(ret.keys()):\n",
    "    ax[i].set_title(stat_key)\n",
    "    for experiment_name in ret[stat_key].keys():\n",
    "        ts, avgs, stds = ret[stat_key][experiment_name]['t'], ret[stat_key][experiment_name]['avg'], ret[stat_key][experiment_name]['std']\n",
    "        if avgs.ndim == 2:\n",
    "            ax[i].plot(ts, avgs.mean(axis=-1), label=experiment_name)\n",
    "            ax[i].fill_between(ts, avgs.mean(axis=-1) - 1.96 * stds.mean(axis=-1), avgs.mean(axis=-1) + 1.96 * stds.mean(axis=-1), alpha=0.2)\n",
    "            # for j in range(avgs.shape[1]):\n",
    "            #     ax[i].plot(ts, avgs[:, j], label=f'{experiment_name} {str(j)}')\n",
    "            #     ax[i].fill_between(ts, avgs[:, j] - 1.96 * stds[:, j], avgs[:, j] + 1.96 * stds[:, j], alpha=0.2)\n",
    "        else:\n",
    "            if stat_key == 'loss':\n",
    "                n = 3\n",
    "                kernel = [1 / n,] * n\n",
    "                avgs = np.convolve(avgs, kernel)[n // 2:n // 2 + avgs.shape[0]]\n",
    "                stds = np.convolve(stds, kernel)[n // 2:n // 2 + stds.shape[0]]\n",
    "            ax[i].plot(ts, avgs, label=experiment_name)\n",
    "            ax[i].fill_between(ts, avgs - 1.96 * stds, avgs + 1.96 * stds, alpha=0.2)\n",
    "    ax[i].legend()\n",
    "    \n",
    "\n",
    "ax[1].set_ylim(-0.2, 0.2)\n",
    "ax[2].set_ylim(-0.2, 0.2)\n",
    "# plt.savefig(f'figs/{NAME}.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-opt",
   "language": "python",
   "name": "meta-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
