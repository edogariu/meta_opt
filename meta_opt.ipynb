{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760f4e7d-a02f-42f3-b87d-231d03392428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for use in google colab!!\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !pip install ./meta-opt\n",
    "# !pip install tensorflow-text ml_collections clu sentencepiece  # for WMT\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# DIR_PREFIX = \"drive/My Drive/meta-opt\"\n",
    "\n",
    "# # for extra one-time setup in colab\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !mkdir meta-opt/data\n",
    "# !mkdir meta-opt/datasets\n",
    "# !cp -r \"meta-opt\" \"drive/My Drive/\"\n",
    "# !pip install kora -q  # library from https://stackoverflow.com/questions/62596466/how-can-i-run-notebooks-of-a-github-project-in-google-colab to help get ID\n",
    "# from kora.xattr import get_id\n",
    "# fid = get_id(f\"{dir_prefix}meta_opt.ipynb\")\n",
    "# print(\"https://colab.research.google.com/drive/\"+fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b898f1e-f002-435a-b1b4-65a21e05a8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import perf_counter\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "from meta_opt.nn.trainer import create_train_state, gradient_descent, reset_model, eval\n",
    "from meta_opt.problems import mnist, cifar10, wmt\n",
    "\n",
    "from meta_opt.meta_opt import MetaOpt\n",
    "from meta_opt.gaps import MetaOptGAPS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730ed64-63a1-46de-8106-28529a15467e",
   "metadata": {},
   "source": [
    "### Todo\n",
    "- add caching to dataloaders\n",
    "- add MP, cosine, cyclical learning rates, hedging, AGD, DoWG, D-adaptation, adagrad & rmsprop\n",
    "- try other settings\n",
    "- check \"training instability\" literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56168648-67e9-4ee2-91b8-38dfe7ae5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    if seed is None: \n",
    "        seed = np.random.randint()\n",
    "        print('seed set to {}'.format(seed))\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    rng = jax.random.PRNGKey(seed)\n",
    "    return rng, seed\n",
    "\n",
    "def get_problem(seed, name, optimizer):\n",
    "    rng, seed = set_seed(seed)\n",
    "    init_rng, rng = jax.random.split(rng)\n",
    "\n",
    "    # get dataset and model\n",
    "    if 'MNIST' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = mnist.load_mnist(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = mnist.MLP([28 * 28, 100, 100, 10])\n",
    "    elif 'CIFAR' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = cifar10.load_cifar10(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = cifar10.VGG(stages=((32, 32), (64, 64), (128, 128)), layer_dims=[128, 10], drop_last_activation=True, dropout=0.1)\n",
    "    elif 'WMT' in name:\n",
    "        train_ds, test_ds, example_input, loss_fn, acc_fn = wmt.load_wmt(NUM_ITERS, BATCH_SIZE, dataset_dir=f'{DIR_PREFIX}/datasets')\n",
    "        model = wmt.make_transformer(num_heads=8, num_layers=6, emb_dim=256, qkv_dim=256, mlp_dim=1024)\n",
    "    else:\n",
    "        raise NotImplementedError(name)\n",
    "\n",
    "    tstate = create_train_state(init_rng, model, example_input, optimizer, loss_fn, acc_fn=acc_fn)\n",
    "    del init_rng\n",
    "\n",
    "    args = {'seed': seed,\n",
    "            'model': str(model),\n",
    "            'params': sum(x.size for x in jax.tree_util.tree_leaves(tstate.params)),\n",
    "            'dataset': name,\n",
    "            'num_iters': NUM_ITERS,\n",
    "            'eval_every': EVAL_EVERY,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'reset_every': RESET_EVERY,\n",
    "            'print_every': PRINT_EVERY}\n",
    "\n",
    "    return tstate, train_ds, test_ds, rng, args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68611b25-ff6c-498a-bac1-30873eac9b16",
   "metadata": {},
   "source": [
    "# Standard Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35553ddc-66dd-454e-9608-8820ba402b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_standard_opt(seed, problem_name, optimizer):\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "    \n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = deepcopy(tstate.opt_state.hyperparams)\n",
    "    args['optimizer_args']['name'] = 'standard'\n",
    "    stats['args'] = args\n",
    "\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        stats[t] = s\n",
    "    \n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4d2163-9b72-4c54-85cc-2abb68c0459f",
   "metadata": {},
   "source": [
    "# Meta-Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907792cd-7420-4e61-a458-372e2dac9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_meta_opt(seed, problem_name: str, m_method: str, meta_lr: float, use_adam: bool, H: int, HH: int, initial_lr: int):\n",
    "    optimizer = optax.sgd(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "    \n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'meta',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'm_method': m_method,\n",
    "                              'meta_lr': meta_lr,\n",
    "                              'use_adam': use_adam,\n",
    "                              'H': H,\n",
    "                              'HH': HH\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "    meta_opt = MetaOpt(tstate, H=H, HH=HH, meta_lr=meta_lr, delta=1e-5, m_method=m_method, use_adam=use_adam)\n",
    "\n",
    "    it = iter(train_ds.as_numpy_iterator())\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            meta_opt = meta_opt.episode_reset()\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        tstate = meta_opt.meta_step(tstate, grads, batch)\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        if m_method == 'scalar': s['M'] = meta_opt.cstate.M.reshape(-1)\n",
    "        else: s['M'] = jnp.stack([m.reshape((m.shape[0], -1)).mean(axis=-1) for m in jax.tree_util.tree_leaves(meta_opt.cstate.M)], axis=0).mean(axis=0)\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3), 'M': s['M'].sum()})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d10045c-53d9-41f3-b559-f7a0c2fe8bf6",
   "metadata": {},
   "source": [
    "# Gradient-based Adaptive Policy Selection (GAPS) Meta-Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5867db6-fe41-4dbd-9934-1a52617cc94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gaps_meta_opt(seed, problem_name: str, m_method: str, meta_lr: float, use_adam: bool, H: int, B: int, initial_lr: int):\n",
    "    optimizer = optax.sgd(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "    \n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'gaps_meta',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'm_method': m_method,\n",
    "                              'meta_lr': meta_lr,\n",
    "                              'use_adam': use_adam,\n",
    "                              'H': H,\n",
    "                              'B': B\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "\n",
    "    meta_opt = MetaOptGAPS(tstate, H=H, B=B, meta_lr=meta_lr, use_adam=use_adam, delta=1e-5, m_method=m_method)\n",
    "    \n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            meta_opt = meta_opt.episode_reset()\n",
    "            del reset_rng\n",
    "\n",
    "        # tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        tstate, (loss, grads) = meta_opt.meta_step(tstate, batch)\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        if m_method == 'scalar': s['M'] = meta_opt.cstate.M.reshape(-1)\n",
    "        else: s['M'] = jnp.stack([m.reshape((m.shape[0], -1)).mean(axis=-1) for m in jax.tree_util.tree_leaves(meta_opt.cstate.M)], axis=0).mean(axis=0)\n",
    "        stats[t] = s\n",
    "\n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3), 'M': s['M'].sum()})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada709b3-489a-44e8-bba2-cfd9221f0988",
   "metadata": {},
   "source": [
    "# Hypergradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f5747-f1ee-43fb-8e9e-5228dd1b3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_hgd(seed, problem_name: str, initial_lr: float, hypergrad_lr: float):\n",
    "\n",
    "    optimizer = optax.inject_hyperparams(optax.sgd)(learning_rate=initial_lr)\n",
    "    tstate, train_ds, test_ds, rng, args = get_problem(seed, problem_name, optimizer)\n",
    "\n",
    "    stats = defaultdict(dict)\n",
    "    args['optimizer_args'] = {'name': 'hgd',\n",
    "                              'initial_lr': initial_lr,\n",
    "                              'hypergrad_lr': hypergrad_lr,\n",
    "                              }\n",
    "    stats['args'] = args\n",
    "    \n",
    "    prev_grads = None\n",
    "    t0 = perf_counter()\n",
    "    for t, batch in enumerate(pbar := tqdm.tqdm(train_ds.as_numpy_iterator(), total=args['num_iters'])):\n",
    "        t += 1\n",
    "    \n",
    "        if t % RESET_EVERY == 0:\n",
    "            reset_rng, rng = jax.random.split(rng)\n",
    "            tstate = reset_model(reset_rng, tstate)\n",
    "            del reset_rng\n",
    "\n",
    "        tstate, (loss, grads) = gradient_descent(tstate, batch)\n",
    "        if prev_grads is not None: \n",
    "            hypergrad = -sum([(g1 * g2).sum() for g1, g2 in zip(jax.tree_util.tree_leaves(grads), jax.tree_util.tree_leaves(prev_grads))])\n",
    "            tstate.opt_state.hyperparams['learning_rate'] -= hypergrad_lr * hypergrad\n",
    "        prev_grads = grads\n",
    "        \n",
    "        # update all the stats\n",
    "        s = {}\n",
    "        s['timestamp'] = perf_counter() - t0\n",
    "        s['loss'] = loss\n",
    "        s['lr'] = tstate.opt_state.hyperparams['learning_rate'].item()\n",
    "        if t % EVAL_EVERY == 0: \n",
    "            s['eval_loss'], s['eval_acc'] = 0., 0.\n",
    "            n = 0\n",
    "            for batch in test_ds.as_numpy_iterator():\n",
    "                loss, acc = eval(tstate, batch)\n",
    "                s['eval_loss'] += loss\n",
    "                s['eval_acc'] += acc\n",
    "                n += 1\n",
    "            s['eval_loss'] /= n\n",
    "            s['eval_acc'] /= n\n",
    "            s['grad_sq_norm'] = sum(jax.tree_util.tree_flatten(jax.tree_map(lambda g: (g * g).sum(), grads))[0])\n",
    "        stats[t] = s\n",
    "    \n",
    "        # print if we gotta\n",
    "        if t % PRINT_EVERY == 0 and t > 0:\n",
    "            idxs = [stats[i] for i in range(t - PRINT_EVERY, t) if i in stats]\n",
    "            avg_train_loss = np.mean([s['loss'] for s in idxs if 'loss' in s])\n",
    "            avg_eval_loss = np.mean([s['eval_loss'] for s in idxs if 'eval_loss' in s])\n",
    "            print(f'iters {t - PRINT_EVERY} - {t}')\n",
    "            print(f'\\tavg train loss: {avg_train_loss}')\n",
    "            print(f'\\tavg eval loss: {avg_eval_loss}')\n",
    "        pbar.set_postfix({'loss': round(s['loss'].item(), 3)})\n",
    "\n",
    "    return dict(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125998da-b7ed-4d07-af09-d2020a813e0a",
   "metadata": {},
   "source": [
    "# Run\n",
    "Select the hyperparameters and the seeds to use for each trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211e988-2b8f-43a1-9ba5-23045d3057d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "SEEDS = [48,] \n",
    "NUM_ITERS = 8000\n",
    "EVAL_EVERY = 100\n",
    "BATCH_SIZE = 512\n",
    "RESET_EVERY = 8000\n",
    "PRINT_EVERY = int(1e10)\n",
    "\n",
    "NAME = 'MNIST'\n",
    "if 'DIR_PREFIX' not in globals(): DIR_PREFIX = '.'  # use this directory if unspecified\n",
    "\n",
    "from jax.lib import xla_bridge\n",
    "print('dataset:', NAME)\n",
    "print('using', xla_bridge.get_backend().platform, 'for jax')\n",
    "print(f'saving data at `{DIR_PREFIX}/data/`')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b5b25-2f17-4c6a-afaa-88f904c1c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the ones to run\n",
    "results = defaultdict(list)\n",
    "# results = pkl.load(open(f'{DIR_PREFIX}/data/{NAME}_raw.pkl', 'rb'))\n",
    "\n",
    "for s in SEEDS:\n",
    "\n",
    "    # standard benchmarks\n",
    "    results['sgd_0.01'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.1)))\n",
    "    results['momentum_0.01'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.sgd)(learning_rate=0.01, momentum=0.9)))\n",
    "    results['adam_0.0001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.adam)(learning_rate=1e-4)))\n",
    "    results['rmsprop_0.001'].append(train_standard_opt(s, NAME, optax.inject_hyperparams(optax.rmsprop)(learning_rate=0.001)))\n",
    "    results['hgd_0.4'].append(train_hgd(s, NAME, initial_lr=0.4, hypergrad_lr=1e-4)\n",
    "\n",
    "    # scalar \n",
    "    results['scalar_0.0004'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.0004, H=36, HH=2, initial_lr=0.01, use_adam=False))\n",
    "    results['scalar_0.0001'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.0001, H=36, HH=2, initial_lr=0.01, use_adam=False))\n",
    "    results['scalar_adam_0.0002'].append(train_meta_opt(s, NAME, 'scalar', meta_lr=0.0002, H=36, HH=2, initial_lr=0.01, use_adam=True))\n",
    "\n",
    "    # diagonal\n",
    "    results['diagonal_0.4'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=0.4, H=36, HH=2, initial_lr=0.01, use_adam=False))\n",
    "    results['diagonal_1.0'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=1.0, H=36, HH=2, initial_lr=0.01, use_adam=False))\n",
    "    results['diagonal_adam_0.0002'].append(train_meta_opt(s, NAME, 'diagonal', meta_lr=0.0002, H=36, HH=2, initial_lr=0.01, use_adam=True))\n",
    "\n",
    "    # the caltech paper\n",
    "    results['meta_GAPS'].append(train_gaps_meta_opt(s, NAME, 'scalar', meta_lr=0.001, H=6, B=6, initial_lr=0.2, use_adam=False))\n",
    "\n",
    "    if len(results) > 0:\n",
    "        with open(f'{DIR_PREFIX}/data/{NAME}_raw.pkl', 'wb') as f: \n",
    "            pkl.dump(results, f)\n",
    "            # print(f'Saved checkpoint for seed #{s}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f1b24-5846-45f3-b20b-ddcd89bf8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the stats\n",
    "for k, v in results.items():\n",
    "    if len(v) == 0: del results[k]\n",
    "\n",
    "aggregated = {}  # experiment name -> 'args' or timestamp -> stat key -> stat value\n",
    "# gather stats\n",
    "for k, v in results.items():  # for each experiment\n",
    "    aggregated[k] = {'args': []}\n",
    "\n",
    "    for n in range(len(SEEDS)):  # for each trial\n",
    "        aggregated[k]['args'].append(v[n]['args'])\n",
    "        \n",
    "        for t in range(1, v[0]['args']['num_iters'] + 1):  # for each timestamp    \n",
    "            for stat_key, value in v[n][t].items():  # for each stat recorded at that timestamp\n",
    "                if stat_key not in aggregated[k]: aggregated[k][stat_key] = {}\n",
    "                if t not in aggregated[k][stat_key]: aggregated[k][stat_key][t] = []\n",
    "                aggregated[k][stat_key][t].append(value)\n",
    "\n",
    "# aggregate stats\n",
    "ret = defaultdict(dict)  # stat key -> experiment name -> 't' or 'avg' or 'std' -> \n",
    "args = {}\n",
    "for k, v in aggregated.items():  # for experiment\n",
    "    for stat_key in v.keys():  # for stat \n",
    "        if stat_key == 'args': \n",
    "            args[k] = v[stat_key]\n",
    "            continue\n",
    "        if k not in ret[stat_key]: ret[stat_key][k] = {}\n",
    "        ret[stat_key][k]['t'] = list(v[stat_key].keys())\n",
    "        arr = np.array(list(v[stat_key].values()))\n",
    "        ret[stat_key][k]['avg'] = np.mean(arr, axis=1)\n",
    "        ret[stat_key][k]['std'] = np.std(arr, axis=1)\n",
    "\n",
    "with open(f'{DIR_PREFIX}/data/{NAME}_processed.pkl', 'wb') as f: \n",
    "    pkl.dump(ret, f)\n",
    "    print('Saved processed results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f13ef9-3e01-4171-b516-a50e90c4c8cf",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d6db68-9bdc-41cc-95eb-ebdfe55807fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(len(ret), 1, figsize=(10, 24))\n",
    "\n",
    "for i, stat_key in enumerate(ret.keys()):\n",
    "    ax[i].set_title(stat_key)\n",
    "    for experiment_name in ret[stat_key].keys():\n",
    "        ts, avgs, stds = ret[stat_key][experiment_name]['t'], ret[stat_key][experiment_name]['avg'], ret[stat_key][experiment_name]['std']\n",
    "        if avgs.ndim == 2:\n",
    "            ax[i].plot(ts, avgs.mean(axis=-1), label=experiment_name)\n",
    "            ax[i].fill_between(ts, avgs.mean(axis=-1) - 1.96 * stds.mean(axis=-1), avgs.mean(axis=-1) + 1.96 * stds.mean(axis=-1), alpha=0.2)\n",
    "            # for j in range(avgs.shape[1]):\n",
    "            #     ax[i].plot(ts, avgs[:, j], label=f'{experiment_name} {str(j)}')\n",
    "            #     ax[i].fill_between(ts, avgs[:, j] - 1.96 * stds[:, j], avgs[:, j] + 1.96 * stds[:, j], alpha=0.2)\n",
    "        else:\n",
    "            if stat_key == 'loss':\n",
    "                n = 3\n",
    "                kernel = [1 / n,] * n\n",
    "                avgs = np.convolve(avgs, kernel)[n // 2:n // 2 + avgs.shape[0]]\n",
    "                stds = np.convolve(stds, kernel)[n // 2:n // 2 + stds.shape[0]]\n",
    "            ax[i].plot(ts, avgs, label=experiment_name)\n",
    "            ax[i].fill_between(ts, avgs - 1.96 * stds, avgs + 1.96 * stds, alpha=0.2)\n",
    "    ax[i].legend()\n",
    "    \n",
    "\n",
    "ax[1].set_ylim(-0.1, 0.7)\n",
    "ax[2].set_ylim(-0.1, 0.7)\n",
    "ax[3].set_ylim(0.85, 1.02)\n",
    "ax[5].set_ylim(-0.05, 0.05)\n",
    "plt.savefig(f'{DIR_PREFIX}/figs/mnist_diagnosis.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba19d7-3966-4d47-9bda-ce1d56709cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-opt",
   "language": "python",
   "name": "meta-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
