{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a792c1-c492-417e-a549-0370570f38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle the system stuff, colab stuff, etc\n",
    "import os\n",
    "try:\n",
    "    from google import colab  # for use in google colab!!\n",
    "    !git clone https://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@github.com/edogariu/meta-opt\n",
    "    !pip install -q ./meta-opt\n",
    "    !pip install -q dill\n",
    "    # !pip install -q jax[cuda12_pip]==0.4.20 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html  # for disabling prealloc, see https://github.com/google/jax/discussions/19014\n",
    "    # !pip install -q tensorflow-text ml_collections clu sentencepiece  # for WMT\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DIR = os.path.abspath(\"./drive/My Drive/meta-opt\")\n",
    "except: \n",
    "    DIR = os.path.abspath(\".\")\n",
    "assert os.path.isdir(DIR)\n",
    "\n",
    "# make sure we have the necessary folders\n",
    "for subdir in ['data', 'figs', 'datasets']: \n",
    "    temp = os.path.join(DIR, subdir)\n",
    "    if not os.path.isdir(temp): os.mkdir(temp)\n",
    "\n",
    "# # for the one-time colab setup\n",
    "# !git clone https://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@github.com/edogariu/meta-opt\n",
    "# !cp -r \"meta-opt\" \"drive/My Drive/\"\n",
    "# !pip install kora -q  # library from https://stackoverflow.com/questions/62596466/how-can-i-run-notebooks-of-a-github-project-in-google-colab to help get ID\n",
    "# from kora.xattr import get_id\n",
    "# fid = get_id(f\"{dir_prefix}meta_opt.ipynb\")\n",
    "# print(\"https://colab.research.google.com/drive/\"+fid)\n",
    "\n",
    "from meta_opt.train_loops import train_standard_opt, train_hgd, train_meta_opt\n",
    "from meta_opt.utils.experiment_utils import make, save_checkpoint, process_results, bcolors, plot, get_final_cparams\n",
    "import meta_opt.configs as configs\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import dill as pkl\n",
    "import optax\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4de7a-d60f-41a0-ab69-ff25351b924c",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8211e988-2b8f-43a1-9ba5-23045d3057d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8211e988-2b8f-43a1-9ba5-23045d3057d3",
    "outputId": "ef881563-f7b8-483c-b35a-523921e95e13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using \u001b[93m\u001b[1mcpu\u001b[0m for jax\n",
      "results will be stored at: \u001b[96m\u001b[1m/Users/evandigiorno/Desktop/meta-opt/data/mnist_pretrained_*.pkl\u001b[0m\n",
      "we will \u001b[91m\u001b[1mNOT\u001b[0m try to load experiment checkpoint first\n",
      "\u001b[91m\u001b[1mWARNING: there already exists a checkpoint with this name! make sure you want to overwrite\u001b[0m\n",
      "starting the experiment from scratch :)\n"
     ]
    }
   ],
   "source": [
    "# configuration and seeds for each trial\n",
    "SEEDS = [2, 3, 4]  # the length of this list is the number of trials we will run :)\n",
    "CFG = {\n",
    "    # training options\n",
    "    'workload': 'MNIST',\n",
    "    'num_iters': 20000,\n",
    "    'eval_every': 100,\n",
    "    'num_eval_iters': -1,\n",
    "    'batch_size': 256,\n",
    "    'full_batch': False,\n",
    "    'reset_every': 4000,\n",
    "\n",
    "    # experiment options\n",
    "    'experiment_name': 'mnist_pretrained',\n",
    "    'load_checkpoint': False,\n",
    "    'overwrite': True,  # whether to allow us to overwrite existing checkpoints or throw errors\n",
    "    'directory': DIR,\n",
    "}\n",
    "\n",
    "results = make(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a76fa482-aba2-4e9e-9e3b-caf40c5bceb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|███▎                                                                                                                           | 521/20000 [00:12<07:43, 42.03it/s, loss=0.123, eval_loss=0.135]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ours\u001b[39;00m\n\u001b[1;32m      9\u001b[0m opt \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39minject_hyperparams(optax\u001b[38;5;241m.\u001b[39madam)(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, b1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, b2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.999\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_meta_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcounterfactual\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHH\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcparams_initial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_cparams\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mncf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_meta_opt(CFG, counterfactual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, HH\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, meta_optimizer\u001b[38;5;241m=\u001b[39mopt, cparams_initial\u001b[38;5;241m=\u001b[39minitial_cparams))\n\u001b[1;32m     12\u001b[0m results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrozen\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_meta_opt(CFG, counterfactual\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, H\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, HH\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, meta_optimizer\u001b[38;5;241m=\u001b[39moptax\u001b[38;5;241m.\u001b[39minject_hyperparams(optax\u001b[38;5;241m.\u001b[39msgd)(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), cparams_initial\u001b[38;5;241m=\u001b[39minitial_cparams))\n",
      "File \u001b[0;32m~/Desktop/meta-opt/meta_opt/train_loops/meta.py:70\u001b[0m, in \u001b[0;36mtrain_meta_opt\u001b[0;34m(cfg, counterfactual, meta_optimizer, H, HH, m_method, initial_lr, grad_clip, dtype, cparams_initial)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counterfactual:\n\u001b[1;32m     69\u001b[0m     tstate, (loss, grads) \u001b[38;5;241m=\u001b[39m train_step(tstate, batch)\n\u001b[0;32m---> 70\u001b[0m     tstate \u001b[38;5;241m=\u001b[39m \u001b[43mmeta_opt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcounterfactual_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     tstate, (loss, grads) \u001b[38;5;241m=\u001b[39m meta_opt\u001b[38;5;241m.\u001b[39mnoncounterfactual_step(tstate, batch)\n",
      "File \u001b[0;32m~/Desktop/meta-opt/meta_opt/meta_opt.py:235\u001b[0m, in \u001b[0;36mMetaOpt.counterfactual_step\u001b[0;34m(self, tstate, grads, batch)\u001b[0m\n\u001b[1;32m    233\u001b[0m     control \u001b[38;5;241m=\u001b[39m compute_control(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcstate\u001b[38;5;241m.\u001b[39mcparams, slice_pytree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_history, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcstate\u001b[38;5;241m.\u001b[39mHH, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcstate\u001b[38;5;241m.\u001b[39mH))  \u001b[38;5;66;03m# use past H disturbances\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     tstate \u001b[38;5;241m=\u001b[39m tstate\u001b[38;5;241m.\u001b[39mreplace(params\u001b[38;5;241m=\u001b[39madd_pytrees(tstate\u001b[38;5;241m.\u001b[39mparams, control))\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcstate \u001b[38;5;241m=\u001b[39m \u001b[43mcounterfactual_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtstate_history\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtstate_history \u001b[38;5;241m=\u001b[39m append(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtstate_history, tstate)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_history\u001b[38;5;241m.\u001b[39mkeys(): \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_history[k] \u001b[38;5;241m=\u001b[39m append(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_history[k], batch[k]) \n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(_cls)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# uncomment the ones to run, with correctly chosen hyperparameters\n",
    "processed_results = pkl.load(open('{}/data/mnist_fullbatch_processed.pkl'.format(CFG['directory']), 'rb'))\n",
    "initial_cparams = get_final_cparams(processed_results, 'ncf')\n",
    "\n",
    "for s in SEEDS:\n",
    "    CFG['seed'] = s\n",
    "    \n",
    "    # ours\n",
    "    opt = optax.inject_hyperparams(optax.adam)(learning_rate=4e-4, b1=0.9, b2=0.999)\n",
    "    results['cf'].append(train_meta_opt(CFG, counterfactual=True, H=32, HH=2, meta_optimizer=opt, cparams_initial=initial_cparams))\n",
    "    results['ncf'].append(train_meta_opt(CFG, counterfactual=False, H=32, HH=2, meta_optimizer=opt, cparams_initial=initial_cparams))\n",
    "    results['frozen'].append(train_meta_opt(CFG, counterfactual=False, H=32, HH=1, meta_optimizer=optax.inject_hyperparams(optax.sgd)(learning_rate=0), cparams_initial=initial_cparams))\n",
    "\n",
    "    # no_adam = optax.inject_hyperparams(optax.sgd)(learning_rate=2e-4)\n",
    "    # results['cf_noadam'].append(train_meta_opt(CFG, counterfactual=True, H=32, HH=2, meta_optimizer=no_adam))\n",
    "    # results['ncf_noadam'].append(train_meta_opt(CFG, counterfactual=False, H=32, HH=2, meta_optimizer=no_adam))\n",
    "\n",
    "    # standard benchmarks\n",
    "    benchmarks = {\n",
    "        # 'sgd': optax.inject_hyperparams(optax.sgd)(learning_rate=0.4),\n",
    "        # 'momentum': optax.chain(optax.add_decayed_weights(1e-4), optax.inject_hyperparams(optax.sgd)(learning_rate=0.1, momentum=0.9)),\n",
    "        # 'adamw': optax.inject_hyperparams(optax.adamw)(learning_rate=1e-3, b1=0.9, b2=0.999, weight_decay=1e-4),\n",
    "        # 'rmsprop': optax.inject_hyperparams(optax.rmsprop)(learning_rate=1e-3),\n",
    "    }\n",
    "    for k, opt in benchmarks.items(): results[k].append(train_standard_opt(CFG, opt))\n",
    "\n",
    "    # other\n",
    "    # results['hgd'].append(train_hgd(CFG, initial_lr=0.1, hypergrad_lr=1e-3))\n",
    "\n",
    "    save_checkpoint(CFG, results, checkpoint_name=f'seed {s}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LTMpnF5ybSr2",
   "metadata": {
    "id": "LTMpnF5ybSr2"
   },
   "source": [
    "# Plot and Animate\n",
    "Plots. Also animates the values taken by the $\\{M_h\\}_{h=1}^H$ coefficients during training. Each $M_h$ multiplies a disturbance from $h$ training steps ago (i.e. 0 is most recent in this plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a523230-566c-4007-b3fa-6f255de46d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results = process_results(CFG, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kkj0hJUA5gkp",
   "metadata": {
    "id": "kkj0hJUA5gkp"
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------\n",
    "# plot a particular set of experiments\n",
    "# ----------------------------------------\n",
    "keys_to_plot = [\n",
    "    'sgd',\n",
    "    'momentum',\n",
    "    'adamw',\n",
    "    # 'rmsprop',\n",
    "    'hgd',\n",
    "]\n",
    "\n",
    "# ----------------------------------------\n",
    "# OR just plot em via regex\n",
    "# ----------------------------------------\n",
    "# keys_to_plot = '.*long.*'  # specific regex\n",
    "keys_to_plot = '.*'  # anything\n",
    "\n",
    "(fig, ax), anim = plot(results, processed_results, keys_to_plot, anim_bounds=(-0.15, 0.05))\n",
    "ax[1].set_ylim(0.,2)\n",
    "# ax[2].set_ylim(0.5, 0.9)\n",
    "ax[3].set_ylim(0, 2)\n",
    "# ax[4].set_ylim(-0.1, 40)\n",
    "# ax[5].set_ylim(-0.05, 0.05)\n",
    "# plt.savefig(f'{DIR}/figs/{CFG['experiment_name']}.pdf')\n",
    "for a in ax: a.legend()\n",
    "plt.show()\n",
    "\n",
    "h = HTML(anim.to_html5_video())\n",
    "display(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b63910b-6f36-4cfe-a509-017152701d72",
   "metadata": {},
   "source": [
    "#### "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "meta-opt",
   "language": "python",
   "name": "meta-opt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
